# SEO記事自動生成システム - 技術仕様書

**作成日**: 2025年12月9日  
**更新日**: 2025年12月9日  
**バージョン**: 1.1  
**ステータス**: 設計フェーズ

---

## 1. プロジェクト概要

### 1.1 目的

複数の外部LLM（Gemini, Claude, GPT）を組み合わせたSEO最適化記事生成ワークフローを自動化するシステムを構築する。

### 1.2 現状と目標

| 項目 | 現状 | 目標 |
|------|------|------|
| 実行方式 | 手動（ファイル受け渡し） | 半自動 + 全自動 |
| 所要時間 | 約2時間/記事 | 30分以下/記事 |
| ファイル管理 | 手動コピー | 自動受け渡し |

### 1.3 システム区分

```
【半自動フロー】人間確認あり
工程-1 → 工程0 → 工程1 → 工程2 → 工程3A/3B/3C（並列）
                                    ↓
                              [人間確認ポイント]
                                    ↓
【全自動フロー】一気通貫実行
工程4 → 工程5 → 工程6 → 工程6.5 → 工程7A → 工程7B → 工程8 → 工程9 → 工程10
```

---

## 2. 技術スタック

### 2.1 全体アーキテクチャ

```
┌─────────────────────────────────────────────────────────────┐
│                        Frontend                             │
│                   Next.js (React)                           │
│              Vercel or セルフホスト                          │
└─────────────────────┬───────────────────────────────────────┘
                      │ REST / WebSocket
┌─────────────────────▼───────────────────────────────────────┐
│                     Backend API                             │
│              ローカル運用（docker-compose）                  │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              FastAPI + LangGraph                     │   │
│  │         (ワークフローエンジン)                        │   │
│  └─────────────────────────────────────────────────────┘   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                    Redis                             │   │
│  │          (ジョブキュー、一時状態)                     │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                      Database                               │
│               Supabase or Neon (PostgreSQL)                 │
│                     顧客別DB分離                             │
│  ┌──────────────┐ ┌──────────────┐ ┌──────────────┐        │
│  │  tenant_a_db │ │  tenant_b_db │ │  tenant_c_db │        │
│  └──────────────┘ └──────────────┘ └──────────────┘        │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                   External LLM APIs                         │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │ Anthropic │  │  Google  │  │  OpenAI  │  │  (将来)  │   │
│  │ (Claude)  │  │ (Gemini) │  │  (GPT)   │  │ DeepSeek │   │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘   │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 技術選定理由

| コンポーネント | 選定 | 理由 |
|----------------|------|------|
| フロントエンド | Next.js | React基盤、SSR対応、顧客向けUI構築 |
| バックエンドAPI | FastAPI | 非同期処理、OpenAPI自動生成、型安全 |
| ワークフローエンジン | LangGraph | 状態管理、human-in-the-loop、並列実行対応 |
| ホスティング | ローカル（docker-compose） | まずはローカルで運用し、実装・運用を固める |
| データベース | PostgreSQL (顧客別) | 物理的データ分離、オンプレ移行容易 |
| ファイルストレージ | Supabase Storage | PostgreSQLと統合、S3互換 |

### 2.3 オンプレ移行パス

本システムは将来的なオンプレ移行を考慮し、全コンポーネントをセルフホスト可能な構成とする。

| クラウド構成 | オンプレ移行時 |
|-------------|----------------|
| ローカル（docker-compose） | Docker / Kubernetes |
| Supabase PostgreSQL | 自前PostgreSQL |
| Supabase Storage | MinIO (S3互換) |
| Redis（任意） | 自前Redis |
| Secrets（`.env` 等） | HashiCorp Vault |

---

## 3. データベース設計

### 3.1 マルチテナント方針

**顧客別DB分離**を採用する。

理由:
- 物理的なデータ分離保証
- 顧客単位のバックアップ/削除が容易
- オンプレ移行時に顧客DBを切り出し可能
- パフォーマンス影響の顧客間波及防止

### 3.2 共通管理DB スキーマ

```sql
-- テナント管理
CREATE TABLE tenants (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    database_url TEXT NOT NULL,  -- 顧客別DB接続先
    created_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true
);

-- LLMプロバイダー設定
CREATE TABLE llm_providers (
    id TEXT PRIMARY KEY,          -- 'claude', 'gemini', 'openai'
    display_name TEXT NOT NULL,
    api_base_url TEXT,
    is_active BOOLEAN DEFAULT true
);

-- LLMモデル設定
CREATE TABLE llm_models (
    id SERIAL PRIMARY KEY,
    provider_id TEXT REFERENCES llm_providers(id),
    model_name TEXT NOT NULL,     -- 実際のモデル名（最新を随時更新）
    model_class TEXT NOT NULL,    -- 'pro', 'standard'
    is_thinking_model BOOLEAN DEFAULT false,
    max_tokens INT,
    supports_web_search BOOLEAN DEFAULT false,
    cost_per_1k_input DECIMAL,
    cost_per_1k_output DECIMAL,
    is_active BOOLEAN DEFAULT true,
    is_latest BOOLEAN DEFAULT true  -- 同クラス内での最新フラグ
);

-- 工程別デフォルトLLM設定（特性ベース）
CREATE TABLE step_llm_defaults (
    step TEXT PRIMARY KEY,
    provider_id TEXT REFERENCES llm_providers(id),
    model_class TEXT NOT NULL,         -- 'pro', 'standard'
    require_thinking_model BOOLEAN DEFAULT false
);

-- テナント別LLMオーバーライド（特性ベース or 直接指定）
CREATE TABLE tenant_llm_overrides (
    tenant_id TEXT REFERENCES tenants(id),
    step TEXT,
    provider_id TEXT REFERENCES llm_providers(id),
    model_class TEXT,                  -- 'pro', 'standard' (NULLなら直接指定)
    model_id INT REFERENCES llm_models(id),  -- 直接指定する場合
    require_thinking_model BOOLEAN DEFAULT false,
    PRIMARY KEY (tenant_id, step)
);

-- テナント別APIキー（暗号化保存）
CREATE TABLE tenant_api_keys (
    tenant_id TEXT REFERENCES tenants(id),
    provider_id TEXT REFERENCES llm_providers(id),
    encrypted_api_key TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (tenant_id, provider_id)
);
```

### 3.3 顧客別DB スキーマ

```sql
-- LangGraphチェックポイント（顧客別DBに保存）
-- ※LangGraph PostgresSaverが使用するテーブル
CREATE TABLE checkpoints (
    thread_id TEXT NOT NULL,
    checkpoint_id TEXT NOT NULL,
    parent_checkpoint_id TEXT,
    type TEXT,
    checkpoint JSONB NOT NULL,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (thread_id, checkpoint_id)
);

CREATE TABLE checkpoint_writes (
    thread_id TEXT NOT NULL,
    checkpoint_id TEXT NOT NULL,
    task_id TEXT NOT NULL,
    idx INT NOT NULL,
    channel TEXT NOT NULL,
    type TEXT,
    value JSONB,
    PRIMARY KEY (thread_id, checkpoint_id, task_id, idx)
);

-- プロンプトテンプレート
CREATE TABLE prompts (
    id SERIAL PRIMARY KEY,
    step TEXT NOT NULL,
    version INT NOT NULL,
    content TEXT NOT NULL,
    variables JSONB,              -- 使用可能な変数一覧
    created_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true,
    UNIQUE (step, version)
);

-- ワークフロー実行
CREATE TABLE workflow_runs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    project_name TEXT,
    status TEXT NOT NULL,         -- 'pending', 'running', 'paused', 'completed', 'failed'
    current_step TEXT,
    prompt_versions JSONB,        -- {"step0": 1, "step4": 2, ...}
    config JSONB,                 -- 実行時設定
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP
);

-- 工程別実行ログ
CREATE TABLE step_executions (
    id SERIAL PRIMARY KEY,
    workflow_run_id UUID REFERENCES workflow_runs(id),
    step TEXT NOT NULL,
    status TEXT NOT NULL,         -- 'running', 'completed', 'failed'
    llm_model TEXT,               -- 使用したモデル
    input_data JSONB,
    output_data JSONB,
    token_usage JSONB,            -- {"input": 1000, "output": 2000}
    error_message TEXT,
    retry_count INT DEFAULT 0,    -- リトライ回数
    started_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP
);

-- 生成ファイル
CREATE TABLE generated_files (
    id SERIAL PRIMARY KEY,
    workflow_run_id UUID REFERENCES workflow_runs(id),
    step TEXT NOT NULL,
    file_type TEXT NOT NULL,      -- 'json', 'md', 'html', 'csv'
    file_path TEXT NOT NULL,      -- Storageパス
    metadata JSONB,               -- {"word_count": 9850, ...}
    created_at TIMESTAMP DEFAULT NOW()
);

-- 監査ログ
CREATE TABLE audit_logs (
    id SERIAL PRIMARY KEY,
    user_id TEXT NOT NULL,
    action TEXT NOT NULL,         -- 'approve', 'retry', 'delete', 'download'
    resource_type TEXT NOT NULL,  -- 'workflow', 'file', 'prompt'
    resource_id TEXT NOT NULL,
    details JSONB,
    ip_address TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 3.4 状態保存の分離方針

**LangGraphチェックポイントは顧客別DBに保存**する。

理由:
- ワークフロー状態も顧客データの一部であり、分離要件に従う
- 顧客DB削除時にチェックポイントも同時に削除される
- オンプレ移行時に状態も含めて移行可能

実装:
```python
# workflows/checkpointer.py
from langgraph.checkpoint.postgres import PostgresSaver

def get_checkpointer(tenant_id: str) -> PostgresSaver:
    """顧客別DBへの接続でチェックポインターを生成"""
    tenant_db_url = get_tenant_database_url(tenant_id)
    return PostgresSaver.from_conn_string(tenant_db_url)

def create_workflow_for_tenant(tenant_id: str) -> CompiledGraph:
    """顧客別のワークフローインスタンスを生成"""
    checkpointer = get_checkpointer(tenant_id)
    return workflow.compile(
        checkpointer=checkpointer,
        interrupt_before=["human_review"]
    )
```

---

## 4. LLM抽象化設計

### 4.1 設計方針

- プロバイダー・モデルの切り替えを設定のみで可能にする
- 新モデル追加時のコード変更を最小限にする
- 工程別・顧客別のモデル指定に対応する

### 4.2 インターフェース定義

```python
# llm/interface.py
from abc import ABC, abstractmethod
from typing import AsyncIterator
from pydantic import BaseModel

class LLMResponse(BaseModel):
    content: str
    token_usage: dict  # {"input": int, "output": int}
    model: str

class LLMInterface(ABC):
    @abstractmethod
    async def generate(
        self,
        messages: list[dict],
        system_prompt: str,
        temperature: float = 0.7,
        max_tokens: int = 4096,
    ) -> LLMResponse:
        pass
    
    @abstractmethod
    async def generate_stream(
        self,
        messages: list[dict],
        system_prompt: str,
    ) -> AsyncIterator[str]:
        pass
    
    @abstractmethod
    async def generate_json(
        self,
        messages: list[dict],
        system_prompt: str,
        schema: dict,
    ) -> dict:
        """JSON出力を保証するメソッド"""
        pass
```

### 4.3 プロバイダー実装

```python
# llm/claude.py
class ClaudeProvider(LLMInterface):
    def __init__(self, model: str, api_key: str):
        self.model = model
        self.client = AsyncAnthropic(api_key=api_key)
    
    async def generate(self, messages, system_prompt, **kwargs) -> LLMResponse:
        response = await self.client.messages.create(
            model=self.model,
            system=system_prompt,
            messages=messages,
            **kwargs
        )
        return LLMResponse(
            content=response.content[0].text,
            token_usage={
                "input": response.usage.input_tokens,
                "output": response.usage.output_tokens
            },
            model=self.model
        )

# llm/gemini.py
class GeminiProvider(LLMInterface):
    def __init__(self, model: str, api_key: str):
        self.model = model
        # Google AI SDK初期化
    
    async def generate(self, messages, system_prompt, **kwargs) -> LLMResponse:
        # Gemini API呼び出し
        pass

# llm/openai.py
class OpenAIProvider(LLMInterface):
    # OpenAI互換（DeepSeek等も対応可能）
    pass
```

### 4.4 ファクトリー

```python
# llm/factory.py
PROVIDERS = {
    "claude": ClaudeProvider,
    "gemini": GeminiProvider,
    "openai": OpenAIProvider,
}

async def get_llm(
    step: str,
    tenant_id: str,
    db: Database
) -> LLMInterface:
    # 1. テナント別オーバーライドを確認
    override = await db.get_tenant_llm_override(tenant_id, step)
    
    # 2. なければデフォルト設定を使用
    if override:
        config = override
    else:
        config = await db.get_step_llm_default(step)
    
    # 3. 特性に基づいて最新モデルを解決
    model = await db.get_latest_model(
        provider_id=config.provider_id,
        model_class=config.model_class,
        require_thinking=config.require_thinking_model
    )
    
    # 4. APIキー取得（暗号化解除）
    api_key = await db.get_tenant_api_key(
        tenant_id, 
        config.provider_id
    )
    
    # 5. プロバイダーインスタンス生成
    provider_class = PROVIDERS[config.provider_id]
    return provider_class(
        model=model.model_name,
        api_key=api_key
    )


async def get_latest_model(
    db: Database,
    provider_id: str,
    model_class: str,
    require_thinking: bool = False
) -> LLMModel:
    """特性に基づいて最新モデルを取得"""
    return await db.query_one("""
        SELECT * FROM llm_models
        WHERE provider_id = $1
          AND model_class = $2
          AND is_thinking_model = $3
          AND is_active = true
          AND is_latest = true
    """, provider_id, model_class, require_thinking)
```

### 4.5 デフォルトLLM割り当て

基本方針: **各プロバイダーの最新モデルを使用**

| 工程 | プロバイダー | クラス | 思考モデル | 選定理由 |
|------|-------------|--------|------------|----------|
| 工程0 | Gemini | Standard | No | キーワード分析精度 |
| 工程1 | - | - | - | GAS実行 |
| 工程2 | Gemini | Standard | No | CSV処理の安定性 |
| 工程3A | Gemini | Standard | No | 並列分析 |
| 工程3B | Gemini | Standard | No | 並列分析 |
| 工程3C | Gemini | Standard | No | 並列分析 |
| 工程4 | Claude | Standard | No | 構造化出力の品質 |
| 工程5 | Gemini | Standard | No | Web検索連携 |
| 工程6 | Claude | Standard | No | 統合・再構成の品質 |
| 工程6.5 | Claude | Standard | No | 構成案の品質 |
| 工程7A | Claude | Standard | No | 長文生成の品質 |
| 工程7B | Gemini | Standard | No | ブラッシュアップ |
| 工程8 | Gemini | Standard | No | ファクトチェック |
| 工程9 | Claude | Standard | No | 最終リライト品質 |
| 工程10 | Claude | Standard | No | 最終出力品質 |

**クラス定義**:
- **Pro**: 最上位モデル（Claude Opus、Gemini Ultra、GPT-4o等）
- **Standard**: 標準モデル（Claude Sonnet、Gemini Pro/Flash、GPT-4o-mini等）

**思考モデル**: 推論過程を明示的に出力するモデル（Claude with extended thinking、o1/o3等）

---

## 5. ワークフロー設計

### 5.1 LangGraphによる実装方針

```python
# workflows/graph.py
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.postgres import PostgresSaver

class WorkflowState(TypedDict):
    workflow_run_id: str
    tenant_id: str
    current_step: str
    
    # 各工程の出力（全てJSON）
    step0_output: dict | None
    step1_output: dict | None
    step3a_output: dict | None
    step3b_output: dict | None
    step3c_output: dict | None
    step4_output: dict | None
    step5_output: dict | None
    step6_output: dict | None
    step6_5_output: dict | None
    step7a_output: dict | None
    step7b_output: dict | None
    step8_output: dict | None
    step9_output: dict | None
    step10_output: dict | None
    
    # メタ情報
    error: str | None
    human_approved: bool

def create_workflow() -> StateGraph:
    workflow = StateGraph(WorkflowState)
    
    # ノード追加
    workflow.add_node("step0", step0_keyword_selection)
    workflow.add_node("step1", step1_competitor_fetch)
    workflow.add_node("step2", step2_csv_validation)
    workflow.add_node("step3_parallel", step3_parallel_analysis)
    workflow.add_node("human_review", human_review_checkpoint)
    workflow.add_node("step4", step4_outline)
    workflow.add_node("step5", step5_primary_sources)
    workflow.add_node("step6", step6_enhanced_outline)
    workflow.add_node("step6_5", step6_5_integration)
    workflow.add_node("step7a", step7a_draft)
    workflow.add_node("step7b", step7b_polish)
    workflow.add_node("step8", step8_factcheck)
    workflow.add_node("step9", step9_final_rewrite)
    workflow.add_node("step10", step10_output)
    
    # エッジ定義
    workflow.add_edge("step0", "step1")
    workflow.add_edge("step1", "step2")
    workflow.add_edge("step2", "step3_parallel")
    workflow.add_edge("step3_parallel", "human_review")
    
    # 人間承認後の分岐
    workflow.add_conditional_edges(
        "human_review",
        lambda state: "step4" if state["human_approved"] else END
    )
    
    # 全自動フロー
    workflow.add_edge("step4", "step5")
    workflow.add_edge("step5", "step6")
    workflow.add_edge("step6", "step6_5")
    workflow.add_edge("step6_5", "step7a")
    workflow.add_edge("step7a", "step7b")
    workflow.add_edge("step7b", "step8")
    workflow.add_edge("step8", "step9")
    workflow.add_edge("step9", "step10")
    workflow.add_edge("step10", END)
    
    workflow.set_entry_point("step0")
    
    return workflow

# 実際のコンパイルは顧客別に行う（3.4節参照）
# compiled = create_workflow_for_tenant(tenant_id)
```

### 5.2 並列実行（工程3A/3B/3C）

```python
# workflows/nodes/step3.py
import asyncio
from typing import Callable, Awaitable

MAX_RETRIES = 3

async def step3_parallel_analysis(state: WorkflowState) -> WorkflowState:
    """工程3A/3B/3Cを並列実行（リトライ対応）"""
    
    # 関数参照を保持（リトライ時に再生成するため）
    step_funcs: list[tuple[Callable[[WorkflowState], Awaitable[dict]], str]] = [
        (step3a_query_analysis, "3a"),
        (step3b_keyword_extraction, "3b"),
        (step3c_competitor_analysis, "3c"),
    ]
    
    # 初回実行
    tasks = [func(state) for func, _ in step_funcs]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # 失敗した工程のみリトライ
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            func, name = step_funcs[i]
            
            # 最大3回リトライ
            for attempt in range(MAX_RETRIES):
                try:
                    # 関数参照から新しいコルーチンを生成してリトライ
                    results[i] = await func(state)
                    break
                except Exception as e:
                    if attempt == MAX_RETRIES - 1:
                        raise RuntimeError(
                            f"工程3{name}が{MAX_RETRIES}回リトライ後も失敗: {e}"
                        )
    
    return {
        **state,
        "step3a_output": results[0],
        "step3b_output": results[1],
        "step3c_output": results[2],
    }
```

### 5.3 エラーハンドリング方針

| 方針 | 内容 |
|------|------|
| フォールバック | **使用しない** |
| リトライ | 同一モデルで再試行（最大3回） |
| 部分再実行 | 工程7Aのみ対応 |
| 並列失敗時 | 失敗した工程のみリトライ |
| タイムアウト | 寛容に設定（工程別に調整） |
| JSON破損 | バリデーション失敗時は再実行 |

### 5.4 タイムアウト設定（暫定）

| 工程 | タイムアウト | 備考 |
|------|-------------|------|
| 工程0 | 60秒 | |
| 工程1 | 300秒 | 外部API依存 |
| 工程3A/B/C | 各120秒 | |
| 工程4 | 180秒 | |
| 工程5 | 300秒 | Web検索あり |
| 工程6 | 180秒 | |
| 工程6.5 | 180秒 | |
| 工程7A | 600秒 | 長文生成 |
| 工程7B | 300秒 | |
| 工程8 | 300秒 | Web検索あり |
| 工程9 | 300秒 | |
| 工程10 | 120秒 | |

---

## 6. ファイル形式

### 6.1 方針

**全工程の入出力をJSON統一**とする。最終出力（工程10）のみMarkdown/HTMLも併用。

理由:
- パース処理の統一
- バリデーションの容易さ
- 構造化データとしての扱いやすさ

### 6.2 ファイル構造

```
/storage/{tenant_id}/{workflow_run_id}/
├── step0_keyword_selection.json
├── step1_competitors.json          # CSVからJSON変換
├── step3a_query_analysis.json
├── step3b_keyword_extraction.json
├── step3c_competitor_analysis.json
├── step4_outline.json
├── step5_primary_sources.json
├── step6_enhanced_outline.json
├── step6_5_integration.json
├── step7a_draft.json
├── step7b_polished.json
├── step8_factcheck.json
├── step9_final_rewrite.json
├── step10_final/
│   ├── article.json              # 構造化データ
│   ├── article.md                # Markdown版
│   ├── article.html              # HTML版
│   ├── meta_info.json
│   └── comprehensive_report.json
```

### 6.3 JSON構造例

```json
// step7a_draft.json
{
  "metadata": {
    "step": "7A",
    "workflow_run_id": "uuid-xxx",
    "created_at": "2025-12-09T10:00:00Z",
    "llm_model": "claude-sonnet-4-20250514",
    "token_usage": {
      "input": 15000,
      "output": 8000
    }
  },
  "validation": {
    "word_count": 9850,
    "target_word_count": 10000,
    "deviation_percent": -1.5,
    "section_count": 12,
    "cta_count": 3
  },
  "content": {
    "title": "ドライバー採用が難しい理由と解決策",
    "sections": [
      {
        "h2": "なぜドライバー採用は難しいのか",
        "h3_list": ["労働人口の減少", "業界イメージの課題"],
        "body": "...",
        "word_count": 1200,
        "phase": 1,
        "four_pillars": {
          "neuroscience": "扁桃体への訴求",
          "behavioral_economics": "損失回避",
          "llmo": true,
          "kgi": null
        }
      }
    ],
    "cta_placements": [
      {"position": 650, "type": "early"},
      {"position": 2800, "type": "mid"},
      {"position": 9500, "type": "final"}
    ]
  }
}
```

---

## 7. プロンプト管理

### 7.1 方針

- プロンプトはDBに保存（オンプレでない場合、プロンプトを顧客に見せない）
- バージョン管理を実施
- テンプレート変数システムを採用

### 7.2 テンプレート変数

```python
# prompts/renderer.py
import re

VARIABLE_PATTERN = re.compile(r'\{\{(\w+)\}\}')

def render_prompt(template: str, variables: dict) -> str:
    """
    テンプレート変数を置換
    
    例:
    template: "キーワード「{{keyword}}」について分析してください"
    variables: {"keyword": "ドライバー 採用 難しい"}
    result: "キーワード「ドライバー 採用 難しい」について分析してください"
    """
    def replace(match):
        var_name = match.group(1)
        if var_name not in variables:
            raise ValueError(f"未定義の変数: {var_name}")
        return str(variables[var_name])
    
    return VARIABLE_PATTERN.sub(replace, template)
```

### 7.3 使用可能変数（工程別）

| 工程 | 変数 |
|------|------|
| 共通 | `{{keyword}}`, `{{target_word_count}}`, `{{strategy}}` |
| 工程4以降 | `{{step0_output}}`, `{{step3a_output}}`, `{{step3b_output}}`, `{{step3c_output}}` |
| 工程6以降 | `{{step4_output}}`, `{{step5_output}}` |
| 工程7A以降 | `{{step6_5_output}}` |

---

## 8. 人間確認フロー

### 8.1 確認ポイント

工程3（3A/3B/3C並列処理）完了後、工程4開始前に人間確認を挟む。

### 8.2 通知方式

1. **Slack通知**: 工程3完了時にSlack Webhookで通知
2. **画面ポーリング**: フロントエンドが定期的にステータスを確認

### 8.3 実装

```python
# api/webhooks.py
async def notify_human_review_required(
    workflow_run_id: str,
    tenant_id: str
):
    """Slack通知送信"""
    webhook_url = await get_tenant_slack_webhook(tenant_id)
    
    await httpx.post(webhook_url, json={
        "text": f"記事生成ワークフローが承認待ちです",
        "blocks": [
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*ワークフロー ID*: {workflow_run_id}\n工程3の分析結果をレビューしてください。"
                }
            },
            {
                "type": "actions",
                "elements": [
                    {
                        "type": "button",
                        "text": {"type": "plain_text", "text": "レビュー画面を開く"},
                        "url": f"https://app.example.com/review/{workflow_run_id}"
                    }
                ]
            }
        ]
    })
```

```python
# api/workflows.py
@router.post("/workflows/{workflow_run_id}/approve")
async def approve_workflow(workflow_run_id: str):
    """人間承認エンドポイント"""
    # 状態を更新してワークフロー再開
    await update_workflow_state(
        workflow_run_id,
        {"human_approved": True}
    )
    
    # LangGraphのチェックポイントから再開
    await resume_workflow(workflow_run_id)
    
    return {"status": "approved", "message": "工程4以降を開始しました"}
```

---

## 9. API設計

### 9.1 エンドポイント一覧

```
POST   /api/workflows                    # ワークフロー開始
GET    /api/workflows/{id}               # ステータス取得
POST   /api/workflows/{id}/approve       # 人間承認
POST   /api/workflows/{id}/retry/{step}  # 工程再実行（7Aのみ）
DELETE /api/workflows/{id}               # キャンセル

GET    /api/workflows/{id}/files         # 生成ファイル一覧
GET    /api/workflows/{id}/files/{step}  # 特定工程の出力取得

GET    /api/prompts                      # プロンプト一覧
GET    /api/prompts/{step}               # 特定工程のプロンプト
PUT    /api/prompts/{step}               # プロンプト更新（新バージョン作成）

GET    /api/llm/config                   # LLM設定一覧
PUT    /api/llm/config/{step}            # 工程別LLM設定更新

WebSocket /ws/workflows/{id}             # リアルタイム進捗
```

### 9.2 WebSocket進捗通知

```python
# api/websocket.py
@router.websocket("/ws/workflows/{workflow_run_id}")
async def workflow_progress(
    websocket: WebSocket,
    workflow_run_id: str
):
    await websocket.accept()
    
    async for event in subscribe_workflow_events(workflow_run_id):
        await websocket.send_json({
            "type": event.type,        # "step_started", "step_completed", "error"
            "step": event.step,
            "progress": event.progress, # 0-100
            "message": event.message,
            "timestamp": event.timestamp.isoformat()
        })
```

---

## 10. セキュリティ

### 10.1 認証・認可

**認証方式**: Supabase Auth（JWT）

**ロール定義**:

| ロール | 説明 | 権限 |
|--------|------|------|
| admin | 管理者 | 全操作可能 |
| operator | 運用担当 | ワークフロー実行・承認・リトライ可能 |
| viewer | 閲覧者 | 閲覧・ダウンロードのみ |

**権限マトリクス**:

| 操作 | admin | operator | viewer |
|------|-------|----------|--------|
| ワークフロー作成 | ✅ | ✅ | ❌ |
| ワークフロー承認 | ✅ | ✅ | ❌ |
| ワークフロー再実行 | ✅ | ✅ | ❌ |
| ワークフロー削除 | ✅ | ❌ | ❌ |
| ファイル閲覧・DL | ✅ | ✅ | ✅ |
| プロンプト編集 | ✅ | ❌ | ❌ |
| LLM設定変更 | ✅ | ❌ | ❌ |
| ユーザー管理 | ✅ | ❌ | ❌ |

### 10.2 実施事項

| 項目 | 対策 |
|------|------|
| 通信暗号化 | ローカルは用途に応じて（本番相当はTLS終端を必須化） |
| APIキー保存 | 暗号化してDB保存（10.3節参照） |
| 認証 | Supabase Auth（JWT） |
| 認可 | ロールベースアクセス制御（RBAC） |
| シークレット管理 | ローカルは `.env` / OSの秘密情報管理（本番はVault等） |
| 監査ログ | 全操作を記録（3.3節 audit_logs） |

### 10.3 APIキー管理

**方針**: 顧客が自身のAPIキーを登録し、暗号化して保存する。

**保管ポリシー**:
- APIキーは暗号化して保存（平文での保持は行わない）
- ワークフロー実行時のみ復号して使用
- 二次利用・外部送信は行わない
- 顧客からの削除要求に即時対応可能

```python
# security/encryption.py
from cryptography.fernet import Fernet

class APIKeyEncryption:
    def __init__(self, key: bytes):
        self.fernet = Fernet(key)
    
    def encrypt(self, api_key: str) -> str:
        return self.fernet.encrypt(api_key.encode()).decode()
    
    def decrypt(self, encrypted: str) -> str:
        return self.fernet.decrypt(encrypted.encode()).decode()
```

### 10.4 データ保護

| 項目 | 方針 |
|------|------|
| 顧客データ分離 | 顧客別DB（物理分離） |
| バックアップ | 日次自動（Supabase/Neon標準機能） |
| 保持期間 | 生成ファイル: 無期限（当面）、ログ: 90日 |
| 削除要求対応 | 顧客DB丸ごと削除で対応 |

---

## 11. ディレクトリ構成

```
/
├── backend/
│   ├── app/
│   │   ├── main.py                 # FastAPIエントリポイント
│   │   ├── config.py               # 設定
│   │   ├── api/
│   │   │   ├── workflows.py        # ワークフローAPI
│   │   │   ├── prompts.py          # プロンプト管理API
│   │   │   ├── llm_config.py       # LLM設定API
│   │   │   └── websocket.py        # WebSocket
│   │   ├── workflows/
│   │   │   ├── graph.py            # LangGraph定義
│   │   │   ├── state.py            # 状態型定義
│   │   │   └── nodes/
│   │   │       ├── step0.py
│   │   │       ├── step1.py
│   │   │       ├── step3_parallel.py
│   │   │       ├── step4.py
│   │   │       └── ...
│   │   ├── llm/
│   │   │   ├── interface.py        # 抽象インターフェース
│   │   │   ├── factory.py          # ファクトリー
│   │   │   ├── claude.py
│   │   │   ├── gemini.py
│   │   │   └── openai.py
│   │   ├── prompts/
│   │   │   ├── renderer.py         # テンプレートレンダラー
│   │   │   └── validator.py        # 出力バリデーション
│   │   ├── storage/
│   │   │   ├── interface.py
│   │   │   ├── supabase.py
│   │   │   └── minio.py            # オンプレ用
│   │   ├── db/
│   │   │   ├── connection.py       # マルチテナントDB接続
│   │   │   └── models.py           # SQLAlchemy models
│   │   └── security/
│   │       └── encryption.py
│   ├── tests/
│   ├── Dockerfile
│   ├── fly.toml
│   └── requirements.txt
│
├── frontend/
│   ├── app/                        # Next.js App Router
│   │   ├── dashboard/
│   │   ├── projects/
│   │   │   └── [id]/
│   │   │       ├── page.tsx        # プロジェクト詳細
│   │   │       └── review/         # 人間確認画面
│   │   └── settings/
│   │       ├── llm/                # LLM設定
│   │       └── prompts/            # プロンプト管理
│   ├── components/
│   ├── hooks/
│   │   └── useWorkflowProgress.ts  # WebSocket接続
│   └── ...
│
└── docs/
    ├── spec.md                     # 本ドキュメント
    └── api.md                      # API仕様
```

---

## 12. 開発ロードマップ

> **`仕様書/ROADMAP.md` を参照**（成果物ベース・ゲート条件付きの詳細計画）

---

## 13. 監視・ログ・運用

### 13.1 ログ設計

**方針**: 構造化ログ（JSON形式）、全ログに`workflow_run_id`を付与

```python
# logging_config.py
import structlog

structlog.configure(
    processors=[
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ]
)

logger = structlog.get_logger()

# 使用例
logger.info(
    "step_completed",
    workflow_run_id=workflow_run_id,
    step="step4",
    duration_ms=1234,
    token_usage={"input": 1000, "output": 2000}
)
```

**ログレベル**:

| レベル | 用途 |
|--------|------|
| INFO | 工程開始・完了、正常処理 |
| WARNING | リトライ発生、遅延検知 |
| ERROR | 工程失敗、例外発生 |

### 13.2 アラート条件

| 条件 | 重要度 | 通知先 |
|------|--------|--------|
| 工程失敗（1回目） | 低 | ログのみ |
| 3回リトライ後も失敗 | 高 | Slack（運用チャンネル） |
| タイムアウト | 中 | Slack |
| DB接続エラー | 高 | Slack |
| LLM API エラー（429等） | 中 | Slack |

### 13.3 通知実装

```python
# monitoring/alerts.py
import httpx

async def send_alert(
    severity: str,
    title: str,
    workflow_run_id: str,
    details: dict
):
    """Slack通知"""
    color = {"high": "danger", "medium": "warning", "low": "good"}[severity]
    
    await httpx.post(SLACK_WEBHOOK_URL, json={
        "attachments": [{
            "color": color,
            "title": f"[{severity.upper()}] {title}",
            "fields": [
                {"title": "Workflow ID", "value": workflow_run_id, "short": True},
                {"title": "Details", "value": str(details), "short": False}
            ]
        }]
    })
```

### 13.4 ログ保存先

| フェーズ | 保存先 | 保持期間 |
|----------|--------|----------|
| 初期 | ローカル標準出力（docker logs等） | 7日（目安） |
| 本番安定後 | Datadog等へ移行検討 | 90日 |

### 13.5 バックアップ・復旧

| 項目 | 方針 |
|------|------|
| DBバックアップ | 日次自動（Supabase/Neon標準） |
| ファイルバックアップ | Storage標準機能 |
| 復旧手順 | 顧客別DB単位でリストア |
| RTO目標 | 4時間以内 |
| RPO目標 | 24時間以内 |

---

## 14. 未決事項・今後の検討

| 項目 | 状態 | 備考 |
|------|------|------|
| 課金・請求 | 未定 | トークン使用量ベース？月額固定？ |
| 負荷テスト | 未実施 | 同時実行数の上限確認 |
| CI/CD | 未構築 | GitHub Actions想定 |
| 詳細な監視ダッシュボード | Phase 4以降 | Grafana等の導入検討 |

---

## 付録A: 用語集

| 用語 | 説明 |
|------|------|
| 4本柱 | 神経科学 / 行動経済学 / LLMO / KGI |
| 3フェーズ | Phase1(Anxiety) / Phase2(Understanding) / Phase3(Action) |
| CTA | Call To Action（問い合わせ誘導） |
| データアンカー | 信頼性を担保する一次情報の引用 |
| LLMO | Large Language Model Optimization（AI引用最適化） |
| human-in-the-loop | 人間確認を挟むワークフローパターン |

---

## 付録B: 参考リンク

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Supabase Documentation](https://supabase.com/docs)
