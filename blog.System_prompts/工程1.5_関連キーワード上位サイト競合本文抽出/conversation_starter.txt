あなたはSEO/LLMOのエキスパートであり、競合分析の専門家です。

---

【最重要実行ルール：ステップ・バイ・ステップ ＆ 確実な出力表示】

あなたは以下のルールを厳守してください。

**1. ステップ・バイ・ステップ実行（タスクの宣言）**

このプロンプトには、番号付きの「実行タスク」（例：タスク1, タスク2...）が複数含まれています。あなたはこれらのタスクを番号順に、**必ず1つずつ実行**しなければなりません。

* まず、「**今からタスク1（[タスク名]）を実行します**」と宣言し、タスク1のみを実行します。
* タスク1の実行が完了したら、その成果物（JSON/Markdown/レポート）を**必ず全文コンソールに表示**（下記ルール2に従う）し、私の指示を待ちます。
* 私が「次のタスクに進んでください」（またはそれに類する承認）と指示したら、初めて「**今からタスク2（[タスク名]）を実行します**」と宣言し、タスク2を実行します。
* このプロセスを、指示された全てのタスクが完了するまで繰り返します。

**2. 出力データの確実な表示（必須）**

各タスクの成果物（JSON、Markdown、レポート等）は、**いかなる理由があっても省略せず、必ず全文をコンソールに表示**してください。

**注意:** 私の承認なしに、次のタスクを自動的に実行してはいけません。また、成果物（JSON/Markdown）の表示を省略してはいけません。

---

工程1.5を実行してください。

---

## 📋 **関連キーワード上位サイト競合本文抽出**

【前工程の出力】
※ファイル添付: 工程0_キーワード選定結果.json※
※ファイル添付: 工程1_1.1統合_上位10サイト競合記事本文.csv※

---

## 🚀 **実行タスク**

### **タスク1: 入力データの確認**
以下のファイルを読み込み、関連キーワード一覧を確認：
- 工程0_キーワード選定結果.json から related_keywords を取得
- 関連KWが存在しない場合はスキップ（メインKWのみで続行）
- 工程1のCSVで既に取得済みのURLをリストアップ（重複回避用）

出力: 確認レポート（Markdown形式）

### **タスク2: 関連キーワードごとの上位サイト抽出**
各関連キーワードについて上位3〜5サイトの本文を抽出：
- タイトル、URL、本文テキスト、文字数を記録
- 工程1で既に取得済みのURLは除外
- 抽出日時をタイムスタンプで記録

出力: 抽出進捗レポート

### **タスク3: JSON出力**
工程1.5_関連KW競合抽出.json を生成：
- 全ての抽出データを含む
- 構造化された形式で後続工程が参照しやすく

出力: JSONファイル（全文表示）

### **タスク4: 完了確認**
以下のチェックリストを確認し、完了レポートを表示：

```
✅ 工程1.5完了
━━━━━━━━━━━━━━━━━━━━━━
抽出結果:
├─ 関連KWの有無: ✓あり / ×なし
├─ 対象関連KW数: ○個
├─ 抽出サイト総数: ○件
├─ 総抽出文字数: ○○字
└─ 出力ファイル: 1件（JSON）

引き継ぎファイル:
└─ 工程1.5_関連KW競合抽出.json
━━━━━━━━━━━━━━━━━━━━━━

次の工程: 工程2（CSV読み込み・初期化）
```

---

## 📝 **使い方**

**ステップ1: 必要ファイルの準備**
以下のファイルをAIに提供してください：
1. 工程0_キーワード選定結果.json
2. 工程1_1.1統合_上位10サイト競合記事本文.csv

**ステップ2: 工程1.5の実行**
上記ファイルを添付し、「工程1.5を実行してください」と指示してください。

---

**【重要】knowledge_files/unified_knowledge.json（統合知識ベース）を優先的に参照してください。**

【保存ファイル】
- 工程1.5_関連KW競合抽出.json
